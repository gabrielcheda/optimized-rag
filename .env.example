# MemGPT Environment Variables
# DO NOT commit this file to version control

# OpenAI Configuration
OPENAI_API_KEY=

# Database Configuration
POSTGRES_URI=

# Web Search Configuration
TAVILY_API_KEY=

LLM_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small

# RAG Configuration
RERANKING_EMBEDDING_MODEL=text-embedding-3-large
CHUNK_SIZE=1200
CHUNK_OVERLAP=150
MMR_LAMBDA=0.7
RRF_K=60
ENABLE_SELF_RAG=True
RELEVANCE_THRESHOLD=0.75
MAX_RERETRIEVE_ATTEMPTS=2
SEMANTIC_SIMILARITY_THRESHOLD=0.8

# Context Compression
ENABLE_CONTEXT_COMPRESSION=True
CONTEXT_COMPRESSION_MAX_TOKENS=2000
CONTEXT_COMPRESSION_SENTENCES_PER_DOC=8

# Temporal Awareness
ENABLE_TEMPORAL_BOOST=True
RECENCY_WEIGHT=0.15
RECENCY_HALF_LIFE_DAYS=30

# Knowledge Graph
ENABLE_KNOWLEDGE_GRAPH=True
KG_MAX_HOPS=2
KG_MIN_CONFIDENCE=0.5

# Advanced Features
ENABLE_COT_REASONING=True
ENABLE_CROSS_ENCODER=True
ENABLE_QUERY_REFINEMENT=True
CROSS_ENCODER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# DW-GRPO (Dynamic Weight Graph Reinforcement Policy Optimization)
ENABLE_DYNAMIC_WEIGHTS=True
WEIGHT_LEARNING_RATE=0.01
PERFORMANCE_TRACKING_WINDOW=100
ENABLE_HIERARCHICAL_RETRIEVAL=True
HIERARCHICAL_CONFIDENCE_THRESHOLD=0.7
ENABLE_TIER_3=True
ENABLE_COST_TRACKING=True

# Evaluation & Monitoring
ENABLE_METRICS_LOGGING=True
METRICS_LOG_INTERVAL=10

# Agent Configuration
MAX_CONTEXT_TOKENS=18000
TOKEN_ALLOCATION_SYSTEM_PROMPT=1000
TOKEN_ALLOCATION_CORE_MEMORY=500
TOKEN_ALLOCATION_FUNCTION_DEFINITIONS=1500
TOKEN_ALLOCATION_RETRIEVED_CONTEXT=8000
TOKEN_ALLOCATION_CONVERSATION=7000

# Context Management
CONTEXT_WARNING_THRESHOLD=0.75
ARCHIVAL_SEARCH_RESULTS = 5  # Number of results to retrieve from archival memory
RECALL_SEARCH_RESULTS = 10   # Number of conversation messages to retrieve
EMBEDDING_BATCH_SIZE = 100   # Batch size for embedding generation
